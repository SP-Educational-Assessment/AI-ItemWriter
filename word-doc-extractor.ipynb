{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e3edcd-5215-4024-a5a8-3cce94141162",
   "metadata": {},
   "source": [
    "# Word doc exrtactor\n",
    "\n",
    "We'll show how to extract text from a Word doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0eb83f8-0e8f-4461-b583-838ffd1a949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b591a7b2-401b-4e8d-a3d5-f9763a4f7623",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'data/ChatGPT.docx'\n",
    "document = Document(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fbc363d-1a77-4f6d-b28f-0d505de0842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feasibility of child-centered research, as defined in this volume, depends on the research questions, the context, the target population, and the methodologies used. The aim of child-centered research is not only to uncover the full range of needs and abilities to reflect the diversity of populations of interest but also to explore child perspectives that may be different from those of adults. In the field of second language assessment, children are sometimes involved to explore their opinion of proposed tasks and investigate their cognitive, attitudinal and behavioural responses during the development of a new assessment at the pilot/trial/field test/user testing stages. Their voices expressing their experiences and thoughts are actively sought by various elicitation methods. Some of their suggestions may be taken on board to improve instruments, processes, and technologies. In this paper I describe how 10-12 year-old children, both native English speakers and English language learners, were actively involved in the development of the British Council’s new English language test for Young Learners through participation in cog-labs, try-outs and several rounds of user testing. Research methodologies consisted of individual online interviews and face-to-face focus groups to elicit children’s views and ideas which then shaped the content and processes of the final assessment product. Mixed methods data sources and analyses (including, as in our case, participatory research with children) were used to ensure triangulation of findings and to achieve useful, multiple measurement of child outcomes that yield results and interpretations endorsed by children themselves.\n",
      "This article contains my reflections on how feasible and realistic child-centred research is, as defined in this volume. I will be arguing that the feasibility of child-centered research depends on a) the research questions, b) the target population, and c) the methodologies used. In my professional and parental experience, child-centered research is less realistic a) in research that addresses questions which are less immediately relevant or rise out of the lives and experiences of children, b) whose target populations are younger age groups, and c) in research with mainly quantitative approaches. However, even these investigations can and usually do include some elements of child-centeredness. \n",
      "Child-centered research sets very high standards for investigators. The aim is not only to uncover the full range of needs and abilities and reflect the diversity of populations of interest but also to explore child perspectives that may be different from those of adults. The question is how to achieve these overarching goals? Apart from a) ethical considerations of using children as participants in research, it is important to b) measure important and relevant child outcomes both directly and indirectly with age-appropriate, culturally and contextually responsive research instruments, c) have representative sampling rather than convenience sampling, and d) design research based on mixed methods, including quantitative and qualitative approaches. Finding the right questions to ask that is of relevance to children’s lives is at least as crucial as answering them. To investigate previously unexplored aspects, initial exploratory research may be used to lead to confirmatory analysis, especially if the measurement instruments or methods are new, and if practical implications are sought. In an attempt to account for the target population’s needs and abilities, researchers need to offer explanations for and treatment of incomplete data. A close investigation of outliers is as important as the analysis of group characteristics. This way the common risk of using false positive findings as evidence for change may be reduced, and the risk of false negative finding is avoided where some important aspects have not been uncovered. Mixed methods data sources and analyses (including, if possible, participatory research with and by children) are necessary to ensure triangulation of findings and to achieve useful, multiple measurement of child outcomes.\n",
      "I will be drawing on my experience of being a) on the Technical Advisory and Expert Groups for OECD’s International Early Learning and Child Well-being Study (IELS) since its inception in 2015, b) a parent whose children have participated in language research conducted at The University of Cambridge in the Language and Rhythm and Listening to Speech in Children projects, and c) a consultant who has been involved in the test development and validation of the British Council’s new test for Young Learners aged 10-12. I will be outlining possibilities and challenges of child-centeredness that I have encountered in these projects. I would like to treat the development and validation of BCYL test as a case study, and will provide examples of best practice from how the team involved children in the decision making processes.\n",
      "Children have traditionally been viewed as dependent and vulnerable, under the care and protection of their legal guardians who are responsible for their safety and welfare. This perspective on the status of children mandates that in research that involves them, responsible adults (parents, school principals, teachers) must act as gatekeepers to allow researchers access through a process of informed consent. This process is ensured by Research Ethics Committees, as well as legal requirements of working with this specific population, such as the Disclosure and Barring Service clearance in the UK. The ethical review process also promotes that research is conducted not only on children but also for them with a clear aim to benefit them. The principle of do not do harm is ensured by rigorous ethical review, thorough risk assessment, and robust safeguarding measures. However, during these processes, the role of the child in research does not have to be explicitly stated. It is assumed that children’s role is a passive one. As a result, traditionally, children have lacked power and their voices have been underrepresented in research studies conducted on and for children.\n",
      "This traditional deficit view of children was changed by the UN Convention on the Rights of the Child (UNCRC) (1989) which aimed to help change ‘the way children are viewed and treated – in other words, as human beings with a distinct set of rights instead of passive objects of care and charity’. As a direct consequence, in the 1990s, there was a paradigm shift in thinking about childhood. It became accepted that childhood is a social construct which is historically and culturally constructed and constituted through dialogue. This new perspective has viewed children as agents and active co-creators of their social worlds (Prout and James, 1990; James and Pout, 2015). This new approach shifted the positioning of children and teenagers in research and resulted in a drive toward a representation of their voices (Alva et al 2022). The argument is that not including children in the consultation about things that affect them only reinforces the status quo and perpetuates their disempowerment. \n",
      "Therefore, the drive for protection of children must be balanced by the need to hear their voices. These seemingly conflicting aims are best illustrated in medical law by the notion of the emerging capacity of children and teenagers to give consent to their own medical treatment. The NHS website in the UK states: “Children under the age of 16 can consent to their own treatment if they're believed to have enough intelligence, competence and understanding to fully appreciate what's involved in their treatment. This is known as being Gillick competent.” However, in medicine, protection is evidently prioritised over autonomy in case a young person refuses medical treatment: “If a young person refuses treatment, which may lead to their death or a severe permanent injury, their decision can be overruled by the Court of Protection.”  (accessed 22 March 2023) \n",
      "As can be seen from the above, medical law takes the key premise of child-centred research, that is, that it is not children’s age, but their relevant developmental characteristics (cognitive, social, emotional, linguistic, metacognitive maturity) that must be taken into account in considerations when involving children in decisions that directly affect them. The notion of Gillick competence recognises that a child’s capacity to engage in decision-making requires the ability to reflect. Children have limited life experiences. In order to for them to be able to reflect, they need to be supported to enable them to understand the risks and benefits of medical treatment.\n",
      "In research, it is similarly important to consider whether children are mature enough to understand the level of potential risks and benefit of taking part to assess their capacity to make decisions about things that directly affect them. If a child does not seem to be fully capable of understanding what they are agreeing to, but still able to express willingness to take part and understand what is expected of them, their ‘assent’ could be accepted but their parents/carers consent must also be sought. Children must be offered the choice to not participate and to withdraw at any point from the research. \n",
      "A recent EU document (EU, 2019) on child-centered approaches across disciplines (social science, education, law and public policy) makes a distinction between child-focused and child-centered research. Child-focused research includes research with children as participants. For research to qualify as child-centered, there must be an explicit focus on children’s varied needs and interests, and children need to be actively involved in the research, with their individual voices heard (EU 2019, p.9, Murray 2019). \n",
      "There are certainly many examples of exemplary child-focused research. The University of Cambridge Primary School is a research-lead primary school in the UK where my children have participated in various studies. Most recently, the Cognition and Brian Sciences Unit and Centre for Neuroscience in Education at the Department of Psychology have conducted the Language and Rhythm in Children study in 2020/2021. Part of this research project involved brain imaging using highly specialised techniques: \n",
      "As a recent comparison reveals there are ethical considerations “Compared to magnetic resonance imaging (MRI), EEG is more affordable, more tolerant to movement, more flexible (it can be used while sleeping, sitting, standing, or laying), and less ethically demanding.” (Hervé 2022). With all three techniques, children are required to sit motionless while they carry out various experimental tasks, see Figure 1-3.\n",
      "It is crucial to obtain the child and parent’s trust and understanding of the research aims to keep them engaged. A recent publication that describes the processes and assessment materials used is Mandke et al (2022). The  was exemplary and providing  was made extremely simple in an online form. The research aims were clearly stated for parents in terms of educational improvement: “Although this research project may not bring any immediate benefits to your child, in due course the information that we obtain will help to improve children's educational experiences and quality of life”, e.g. to help identify and diagnose developmental dyslexia and developmental language disorders (previously called specific language impairment) and offer remedial treatment. With these strong educational implications sought, the use of longitudinal and interventional design is recommended (Goswami 2020). The current Listening to Speech research pilot in 2023 is an ongoing study with the aim to “develop novel computerised tasks to measure the speech processing skills related to reading”.\n",
      "These studies are exemplary in managing the expectations of the child participants and their parents. They are strongly child-focused with the aim to bring benefits to children and create enjoyable ways of measuring variables of interest. Researchers always gain the child’s assent to play the ‘games’ which are the assessments. Participation is voluntary and children can withdraw any time from the activities. However, given the research questions, it is not always feasible to negotiate every aspect of the tasks with children (Goswami, 27 March 2023, personal communication), therefore they could not be classified as child-centred as defined in this volume and by EU (2019). It would be interesting to find out about participating children’s understanding of the purpose of the research and what they are contributing to, and whether the involvement in research is meaningful for them. It would also be interesting to find out about those children’s thoughts who decide not to take part or who decide to withdraw.\n",
      "The above educationally important studies demonstrate that it is not always feasible for children to play an equivalent (or even minor) role in the design and conduct of research even if they were to be trained and supported in some aspect or stage of the research process. This is despite the fact that there is evidence of the benefits of including them: active participation in research raises the confidence, motivation, and aspirations of children, increases empathy, communication and cognitive skills, encourages responsibility, allows the child to learn how to make decisions, gain independence and take control (Robinson 2014). \n",
      "In fact, it has been demonstrated that children are capable of reporting on their experiences and are competent to express their views from a very young age (see, for example, Clark, McQuail and Moss 2003, Day 2010). Therefore, it is possible to conduct research in collaboration with even very young children where they have a more are active role in the research process. \n",
      "One of these studies is the OECD’s IELS which I have contributed to as a member of the technical advisory expert group. IELS seeks to elicit 5-year-old children’s voices through verbal and visual means as well as through observation and conversation with each individual child. IELS researchers wanted to include a small subset of questions in the study from a wide range of possible question types collected from various sources. The approximate administration time was set at 1-3 minutes. Various question formats were considered and some tried out in the field test: a) multiple choice format, b) binary scale, yes/no questions c) self-report using smiley’s, d) picture vignettes with related questions. Finally it was agreed that asking open-ended questions is a great way to get to know about children’s inner world, personal preferences and generally to allow them to show a window into their personality and uniqueness. Engaging children in a short conversation by the test administrator at the end represented a welcome break from the direct assessment protocol.\n",
      "The aim was to integrate children’s own thoughts on what they enjoy and what they want to do or be when they grow up with the other child outcomes measured directly and indirectly in the study (OECD 2020). The findings from the first round of IELS show a direct relationship between children’s views and perspectives on their lives and their social, cognitive and emotional development. Questions such as “What do you like best about your centre or school?” elicited clear and often very specific responses from almost all five-year-olds. Children were able to reflect on their favourite activity (play; arts and crafts such as drawing, building, construction; and learning activity such as handwriting, looking through books (OECD, 2021c, p.3-8). Perhaps not surprisingly, there is a direct relationship between children’s positive views on learning activities and their early learning outcomes, especially in the cognitive domain (emergent literacy, emergent numeracy, working memory and mental flexibility) as well as their social-emotional development. Curiosity and empathy are two traits that mediate these relationships (OECD 2021a, p.6). Another strong finding was that children who said they liked to choose their activity, demonstrating autonomy and independence, had early learning scores that were significantly higher than average, across a range of domains. “Similar to children who state that learning is their preferred activity, children who most like choosing have higher emergent literacy and emergent numeracy than other children. In addition, children who like to choose the activities they undertake also have significantly higher levels of self-regulation, pro-social skills and trust than other children” (OECD 2021c, p.13). Children’s career aspirations were also linked to their outcomes: children who would like to be scientists and engineers had higher emerging oral language skills, and those who would like to work with animals or teach had higher social emotional skills (OECD, 2021b, p.11). \n",
      "The children’s responses to these questions added critical information on correlates of cognitive and non-cognitive skills assessed. These topics have large policy and analytical value, as a related study on social and emotional skills among 10-15 year olds (OECD 2021d) also shows. In SSES, intellectual curiosity and persistence in efforts are the skills most strongly related to higher school performance for both 10- and 15-year-olds. It is important to continue to think of new ways to elicit children and teenagers’ views. These OECD studies measure some aspects of children and teenagers’ learning and educational aspirations, however, “there is in general a lack of data on children’s understandings of how their actions, behaviours, skills, and abilities may (or may not) impact on their well-being, both now and in the future” (OECD 2021d, p.21). This same report talks about the benefit of collecting children’s and young people’s views by the concept of eudaimonia (psychological “flourishing”, happiness, welfare): “capturing whether people feel that the things they do in life are worthwhile, but can also include self-perceptions of autonomy, capabilities, competence, sense of purpose, locus of control, and other aspects of psychological well-being or flourishing.“ Allowing children and teenagers to express their opinion and even make decisions in research would increase their sense of wellbeing. Children and teenagers should think This study sounds interesting. Perhaps I could help – I haven’t been asked yet but hopefully someone will ask me soon, rather than I do not understand what this study is about/trying to do. I’m sure I cannot help. I’m never going to be asked anyway.\n",
      "However, working with the research teams in IELS has demonstrated to me that eliciting children’s views and accommodating their preferences is not without methodological difficulties. Adult researchers need to overcome the unsymmetrical power relations, achieve rapport to gain the trust, confidence and cooperation of children, and use techniques that help elicit and interpret their thoughts, such as visual methods, self-report data, vignettes and story-based methods. It is important not just to listen to children, but to listen very closely to hear their views (Murray 2019, Rinaldi 2006) without the reference framework of adult-centred norms and perspectives. Interpreting the results requires caution and sensitivity as well as triangulation where child self-report data compliments other measures (such as direct objective measures, and parent or teacher reports) (OECD 2021d, p.46). My experience shows that research on, for and with children is difficult but entirely possible. It requires highly skilled, specially trained and experienced professionals. \n",
      "Child centred research can use traditional adult-led qualitative methods, such as observations, interviews and focus groups. Elicitation methods can include more structured activities designed by adults, such as worksheets, vignettes, diaries, sentence completion, spider diagrams. However, in order to correct the power relations and redress the deficit view of children, the UN Convention advocates children’s right to express their views in any format they wish to, through art, visual methods, games and so on. Adults need to devise ways to allow them to express their views in any form of communication “either orally, in writing or in print, in the form of art, or through any other media of the child’s choice.” (). Many participatory techniques have been used, such as storytelling, puppets, drawings, photographs, graphics, artifacts, photovoice, painting, role play, model-making, collage, games, music, dance, drama, cameras, mapping exercises, child-led tours, blogs, videos, television, radio productions, and digital technologies (Coyne and Carter, 2018; Crivello et al., 2009, Driessnack and Furukawa 2011). \n",
      "Therefore researchers should consider allowing children choice or some control over how they wish to participate. Do children have a say in how they want to provide their opinion and experience? They could, for instance, be asked whether they wished to participate with or without parent/teacher, whether they would like to draw or have a conversation, answer questions individually or in focus groups, or what format from the available formats they might wish to provide their contribution. \n",
      "In test development, before a new test is launched, it is customary to involve learners as one - probably the most important - group of stakeholders. In these research studies, learners’ response data and experiences are taken as evidence to help finalise features of the test administration and the content of the tests. In case of negative views, test features may be improved. User feedback may go sometimes ignored, usually with the assumption that they reflect only a small minority of test takers’ opinion. \n",
      "In a related set of investigation, after a test is operationalised, learners’ cognition, perceptions and experiences are taken as crucial evidence for validation of test features. In these studies, learners’ responses (both empirical and attitudinal) are used to secure and evidence buy-in and endorsement of features and acceptance of assessment products (e.g. Brown 1993). \n",
      "There are several ways to elicit ranking or Likert-type responses in developmentally appropriate, child-friendly activities. Sim and Horton (2005) investigated the performance and attitude of 7-8 year old children in computer based versus paper based testing. The researchers asked children to complete a smarty-o-meter (Figure 4). Children were given five Smarties (chocolate sweets) and asked to distribute them between the computer and paper based test. This was designed to measure their level of preference of one delivery mode over another as opposed to simply asking them their preference. Children were also asked verbally whether they would prefer to use paper based or computer based tests in school to see if this differed to the results from the smarty-o-meter.\n",
      "In a study on test development, Khabbazbashi et al (2021) asked children to express their opinion to statements, using smileys representing a 5-point Likert-scale, see Figure 5. The authors explain, that after the first administration of the questionnaire and feedback from children’s teachers, the statements were changed into adjectives. In both of these studies, children were used as a whole group, and findings were not differentiated by variables of interest (girls/boys, weaker/stronger students, country of residence, etc.) \n",
      "Papp and Walczak (2016) investigated children’s performance and opinion on the paper/face-to-face delivered versus the computer delivered version of Cambridge Young Learners Starters, Movers and Flyers tests. Since, surprisingly, boys were found to outperform girls on both the paper- and CB-delivered version of the test, the researchers ran a series of regression analyses to see links between child outcomes (test performance and attitudes) and background variables (age, gender, L1, years of English study, proficiency level, computer device used in the test, frequency and purpose of computer use, preference for delivery mode, etc.). Another finding was that those candidates who preferred computer delivered tests performed better on both delivery modes than those who preferred the paper-and-pencil version. Importantly for this paper, the study elicited participating children’s views through visual and verbal means, including smileys and drawings. Children could choose to respond in writing or visually. Drawings were classified as positive, negative and neutral. The children’s visual and verbal responses were analysed according to classical content analysis (Morgan, 1997) and constant comparison analysis (Strauss & Corbin, 1998). The qualitative sources of evidence (i.e., testimonials, verbal and graphical comments) were carefully examined for common themes emerging. The opinions were categorised by candidate background variables (i.e., age, gender etc.) that were obtained in the questionnaires and added in the regression analyses. This was done to confirm findings and interpretation of statistical results, as is conventionally done in a convergent mixed methods design. Some of the most positive feelings were expressed by boys, as the sample drawings and verbal comments demonstrate (Figure 7 boy and Figure 8 girl). \n",
      "A similar elicitation technique, method of analysis and interpretation was used in Winke et al (2015, 2018), in a study that belongs to the second type - validation of an operational test. Children (12 ELL learners and 7 native English speakers aged 7 to 9) were asked to draw pictures about Bronze and Silver of the Michigan tests for young learners, the sister suit of exams to Cambridge Young Learners tests, first developed in 1997 for 7-12 year-old children. The authors had children draw a picture about their experience of taking the tests and interviewed them afterwards in a structured interview. They guided the children through a list of standard questions about their drawings and experience of taking the tests (Winke et al. 2015:25) to probe deeper into the child’s opinions and experience:\n",
      "The researchers asked questions in a stimulated recall in order to understand what children thought about the test, how they found a correct answer, or how they decided on their responses to probe into cognitive strategies. The study is valuable for the explanation of the method of coding and analysis of the visual and verbal data in Nvivo. The following drawings (reproduced in Figure 9) appear in the report as illustrations (also in the online supporting document accompanying the 2018 article):\n",
      "In a later study on children’s experiences of taking the TOEFL Primary Speaking exam, Lee and Winke (2018) also used drawings and stimulated recall interviews as elicitation methods based on Carless and Lam (2014). In their study, non-native English speaker learners expressed nervousness and embarrassment as well as stress (pressure of producing accurate and well formulated utterances), as the middle picture in their illustrative sample drawings demonstrates (Figure 10).\n",
      "As can be seen from these studies, drawing as a research technique is practical, time-efficient, and popular with children. However, interpreting drawings requires complex analysis. One of the analytical method that could be used to interpret children’s drawings is Kelly’s Personal Construct theory (Kelly 1955). It is important to confirm children’s meaning in an interview, so the best version of this technique is to use a combination of drawing, writing and talking. \n",
      "Starting in early 2020, the British Council (BC), in collaboration with Metametrics (MM), designed and developed a new multistage adaptive test for 10-12-year-old learners of English. The aim of the test is to support children’s transition between primary and secondary school with accurate measurement of children’s English proficiency. The concept and design principles were laid down in spring 2020. After the test blueprint was developed, a prototype test was created, which was tried out in winter 2020 with the help of 26 children. The data generated was intensively scrutinised and analysed to validate the proof of concept prototype test. Then in July and September, another 15 children participated in two rounds of coglabs to further collect cognitive validity evidence and fine tune aspects of the test and administration. Finally, in the large scale field test, groups of children were asked to participate in focus groups to express their opinions and give suggestions on the new test. The rest of the article describes these studies and how children were actively involved in the test development process.\n",
      "The tryout sample consisted of 26 children from 13 countries: Italy, Bulgaria, Sri Lanka, India, Spain, China, Greece, Brazil, Georgia, Bahrain, Colombia, Thailand, and Vietnam (Table 1), between the ages of 9-12 (Table 2), both genders equally represented (Table 3). Overall, the sample was well distributed along the target ability levels (CEFR Pre-A1 to B1).\n",
      "Research participants were recruited through the British Council’s communication channels (via email). Due to Covid-19, the choice of research site for tryouts was children’s home with their parent’s presence and possible support. Tryout sessions were conducted on Zoom following predesigned protocols (consisting of admin notes laying out roles and responsibilities, consent forms, tryout interview script, and observational sheet) and videorecorded for analysis. Timing of sessions was carefully planned to avoid clashes with children’s other commitments. Sessions were scheduled mainly in late afternoons for the children, some were on weekdays, some on weekends. The interviews were conducted in the child’s L1 and included structured interview questions. Apart from the child participant, there was a facilitator, an interpreter (sometimes the parent), and an observer in each tryout session. The prototype test materials were presented on Powerpoint slides that included some animation with shared screen. \n",
      "The expectations of the child participants and their parents were carefully managed. Children were briefed of their role in the research (that it was not their proficiency in English researchers were interested in but how they interacted with the test tasks and their experience of taking the test, including a consultant role on what could be done to improve aspects of the test. Children understood the purpose of the research and what they were contributing to, making their participation meaningful. All information on the research and test materials was provided to the children in an accessible way (in their L1). Incentives were offered in the form of an appreciation voucher as thankyou for participation for children (see specific advice on remuneration in INVOLVE, 2016). Use of all data collected was clearly explained in a simple way so that all participating children understood. It was clear to the children that they can withdraw their presence and data any time from the research without any consequences (including compensation). After the introduction outlining the above, children’s individual consent was sought (beyond their parents previous consent), and they were asked for their permission to record the session. All procedures that characterise child focused research were followed (see UKRI ESRC website, based on Morrow 2009; Save the Children, 2004).\n",
      "They were asked to state which task they enjoyed most and which task they disliked. This was facilitated by a visual illustration to remind them of all the task types. Asking them to identify the task they most liked and the task they most disliked makes this elicitation method a simplified version of the diamond sorting exercise (Thomas and O’Kane 2000, O’Kane 2008).\n",
      "The observational, interview and scores on dichotomous items, and child spoken and written response data were separately analysed by two BC team members then all data was aggregated. One team coded all qualitative interview and observational data after agreeing on the coding scheme. They calculated descriptive statistics for objective items (percent accuracy, point-biserial correlation), including task timings. Inter-coder reliability was checked. Both coders coded separately data from 11 participants (46% of total participants). An agreement of 96.42% was reached (700 out of 726 total coding instances).\n",
      "The second team transcribed all speaking and writing responses, measured them in terms of time and word count, then coded them according to methods of discourse analysis (functional requirements coding based on O’Sullivan et al (2002)) and corpus analysis (linguistic features using TextInspector). Intercoder reliability was checked on one student’s entire response set. Only 15% (26/177) of the codes assigned were different between the two coders. All disagreements were discussed and agreement reached, with clarifications added to the coding scheme. Although no universally accepted benchmark regarding the percentage of exact agreement is available (Saldana, 2009), 80% has been proposed as a rule of thumb (McHugh, 2012). The data was colour coded using red for the fewest/lowest/slowest responses, amber for average, and green for most/highest/fastest instances. This helped with estimating timing, target word count and functional coverage. It also helped identify the outliers (potentially those who should have been given an easier or harder task in the tryout). It also crucially helped identify a typical candidate / performance for various purposes (test specifications, communications, sample responses)\n",
      "The aim of the intensive data analysis was to find out what is working and what is not working. All coding and analysis focused on this, and children’s behavioural and cognitive data and their opinions on each task were taken together as evidence on the robustness or otherwise of the test and task design and test procedures.\n",
      "Limitations were noted. The small sample sizes (n=26) limited score interpretation, therefore findings were to be treated as indicative and checked at field test. The administration of the prototype test on a shared screen with the use of a Powerpoint meant that children had to give their test responses to the facilitator and did not have control over the test administration. It was noted that facilitator behaviour sometimes might have influenced students (in the case of rushed, shy children, etc.). There were connectivity and other technical issues. In the interviews students’ answers were sometimes ambiguous and not all students gave full answers. It was noted that other elicitation and analysis methods might be needed, possibly introspection for listening and reading strategies, and phonological analysis (in Praat) for hesitation and other speech phenomena.\n",
      "Key findings indicated that with some exceptions, overall, discrete items worked as expected, most discriminate among students well and would facilitate routing in the multistage test. Productive responses were on the whole as expected in terms of key features (use of target functions, length, and linguistic complexity). Analysis of response data showed that the test design (multiple stage adaptive test) would allow for the demonstration of students’ ability. Coverage of CEFR descriptors and analysis of responses indicated that there was a need for more B1-level input to elicit responses at the higher-levels (B1). \n",
      "Observed student behaviours in the tryout indicated a general engagement and interest in the test. Novel and interesting tasks seemed to contribute to student engagement. Children liked the video retell task; compare pictures and write task; map task; and the photo album. They liked to express their opinion, use their imagination, aided by the illustrations and the story line. Tasks that children have done in class seemed boring or too easy to children: the gap fill with no pictures and just words; listen and number sentences; read aloud; weather notes writing; and re-order words in email. Children indicated that they would like more animation. Students responded to most tasks as expected, although there were indications that instructions would need to be reworked to allow for more natural interaction. Interview data showed that students liked the story line and characters, and that they enjoyed the tasks. No issues of cultural sensitivity arose. Student engagement and interest in the prototype test was taken as key evidence of the age appropriateness of the test.\n",
      "The student sample in the coglabs consisted of 15 children from 5 countries (Table 5) between the ages of 9-13 (Table 6) both genders (Table 7). As the CEFR categorization below was based on teacher-reported student proficiency and not validated prior to, during, or after the tryout, the levels are for reference only.\n",
      "The coglabs were conducted in a similar way to the tryouts. When recording, we pinned the window of the test taker to be able to observe their reactions even when they were not talking. We considered using a second camera pointed at the keyboard. Children’s test taking behaviors were closely observed and queried. Here children were asked about their thoughts following each task in a Q&A sequence. After taking the test, children were interviewed in their L1 through the help of an interpreter. \n",
      "The analysis of the data also followed the tryout. All data were compared with Tryout data. The findings were instrumental in finalizing the assessment content and processes. Based on the results of the intensive coglabs, some tasks were further revised and cognitive requirements fine-tuned (e.g. in terms of prompts, timings, graphics (size, colour, detail, clarity), instructions, word count of input and expected response, layout, scaffolding in the form of a word bank and/or visual support to free up cognitive space, enabling features such as a highlighter, etc.). \n",
      "There were several takeaways from the tryout and the coglabs and the following validation analysis. The cyclical quality checks and reviews and ensuing revisions to the test and delivery platform resulted in useful high quality data from the children. Children’s views were taken into account in the following areas: some more traditional, less popular tasks were dropped and replaced by tasks measuring at a higher level of the CEFR, the cognitive challenge in some tasks was adjusted, and task features (graphics, instructions, prompts) clarified. No issues of cultural sensitivity arose. The extensive validation has ensured that the test developers have adequate analysis to defend test design choices and are able to clearly communicate these internally and externally. Additionally, the rich data that the tryout and coglabs generated were used for the purpose of assessment scale development and validation and reporting of results.\n",
      "Interviews with parents of the children helped triangulate the children’s responses in the coglabs. In some cases, children were able to install the application and check their computer for necessary technical settings. Where technical issues arose, some children proved to be more knowledgeable than their parents.\n",
      "In the subsequent field test in Spring 2022, in which around 1300 candidates took part, focus groups where used with children in face-to-face situations in 4 countries: Taiwan, UAE, Hungary and Colombia. Children’s initial responses were sought right after taking the test on a 10-question short survey using the symbols of thumbs up, neutral and thumbs down (Figure 11).\n",
      "The themes of the questionnaire related to the features of the test and its administrative processes (the digital nature of the test administration, test functionality, test length, timing, instructions, test components). Children’ responses to the 10 areas of interest were analysed in the break. After some warm-up activities (e.g. solving a large puzzle together as a group), the issues arising out of their responses to the short questionnaire were discussed as a group. Boyden and Ennew (1997). Results from all children who gave responses to the short questionnaire are summarized below (Figure 12).\n",
      "Overall, the children found the technology easy to use. Instructions are pitched at the right level. There were many written comments about how the test length was too long and that the children were not given sufficient time to complete each task. This is also reflected in the percentages above. A few commented that the platform was slow and buggy, which did not help the test experience, and made the test feel overly long. Many students struggle with the Speaking and Writing tasks. A few mentioned that technical difficulties with their microphones affected their speaking. A majority enjoyed the test as a whole. \n",
      "BC followed best practice in child-centered research during test development and validation. Children’s experiences of the prototype test and their opinion of what could be changed were used to improve the test. Test developers made all effort to respond to children’s needs and wishes. Thus the BCYL test development serves as a good example of “involving students in conversations about constructs of and expectations for assessment” (Baker et al., 2021, p. 163) where they are treated as “active participants whose insights are welcomed and voices heard”. Students who took part were enabled to experience and rehearse essential reflection and communication skills. \n",
      "The BC’s methodology in the tryouts, coglabs and user testing sessions was to elicit learners’ insights, perceptions, reactions, and feedback. The aim was to validate adult assumptions made, but also to see the test from children’s perspective in order to improve instruments and processes. In line with Butler et al (2021), children participating in the BCLY tryout and field tests have demonstrated that young learners aged 9-12 are capable of making critical and constructive evaluations of language assessments.\n",
      "In this paper I outlined (1) definitions of child-focused and child-centred approach to research with close reference to past or current research; (2) possibilities and challenges for conducting child-focused/child-centred language research; and in the following I offer (3) suggestions for future directions. \n",
      "In child centred research, mixed methods data sources and analyses (including, if possible, participatory research with and by children) are necessary. This will not only benefit children,  ensure triangulation of findings but also will provide useful, multiple measurement of child outcomes and yield results and interpretations endorsed by children themselves. \n",
      "However, children, just like adult researchers, need initial training in such roles. We wanted to find out whether children an be involved in the dissemination of research. This paper has been simplified with the help of ChatGPT. Two of the children participating in the BCYL tryouts, coglabs, user testing, and field test have been asked to act as  to make sure that the research and its findings are appropriate for a 10-12 year old readership. The simplified version can be found on the following link <URL>.\n"
     ]
    }
   ],
   "source": [
    "for para in document.paragraphs:\n",
    "    text = para.text\n",
    "    paraLen = len(text)\n",
    "    if paraLen > 300:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f2b11-478d-44eb-806e-343d2f36e955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
